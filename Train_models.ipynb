{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dropout, LSTM, Embedding, concatenate, Flatten, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from processing import get_class_weights, get_prior, merge4Vectors, read_data, prepare_input\n",
    "from processing import multiclass_encode_labels, apply_standard_scaler, apply_cat_encoder, binary_encode_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stops model training if validation loss does not improve over five subsequent epochs.\n",
    "Documentation: # https://keras.io/api/callbacks/early_stopping/\n",
    "\"\"\"\n",
    "\n",
    "EarlyStopCallback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(N_features, N_cat_features, print_model=True, learning_rate=1e-4):\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    initializer = tf.keras.initializers.HeNormal(seed=0)\n",
    "\n",
    "    input = Input(shape=(N_features,))\n",
    "    input_cat = Input(shape=(N_cat_features,))\n",
    "\n",
    "    unique_cat = 8\n",
    "    embedding_size = 100\n",
    "    embedding_cat = Embedding(unique_cat, embedding_size)(input_cat)\n",
    "\n",
    "    x_c = Dense(128, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(input_cat)\n",
    "    x_c = Dropout(0.125)(x_c)\n",
    "    x = Dense(128, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(input) \n",
    "    x = Dropout(0.125)(x)\n",
    "\n",
    "    merged = concatenate([x_c, x])\n",
    "    x = Dense(128, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(merged)\n",
    "    x = Dropout(0.125)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[input, input_cat], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    if print_model:\n",
    "        print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def binary_LSTM(N_features, N_cat_features=0, print_model=True, learning_rate=1e-5):\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    initializer = tf.keras.initializers.HeNormal(seed=0)\n",
    "    \n",
    "    input = Input(shape=(N_features, 4), name='4-vector')\n",
    "    input_cat = Input(shape=(N_cat_features,), name='OBJ')\n",
    "    input_MET = Input(shape=(2,), name='MET')\n",
    "    unique_cat = 8\n",
    "    embedding_size = 100\n",
    "    embedding_cat = Embedding(unique_cat, embedding_size, name='OBJ_Embedding')(input_cat)\n",
    "\n",
    "    x = concatenate([embedding_cat, input])\n",
    "    x = Bidirectional(LSTM(100, activation='relu', return_sequences=True, \n",
    "                           kernel_initializer=initializer, recurrent_dropout=0.125))(x)\n",
    "    x = Bidirectional(LSTM(100, activation='relu', kernel_initializer=initializer,  recurrent_dropout=0.125))(x)\n",
    "\n",
    "    x_MET = Dense(64, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(input_MET) \n",
    "    merged = concatenate([x_MET, x])\n",
    "    x = Dense(64, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(merged) \n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[input, input_cat, input_MET], outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    if print_model:\n",
    "        print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "def multiclass_LSTM(N_features, N_cat_features=0, print_model=True, learning_rate=1e-5):\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    initializer = tf.keras.initializers.HeNormal(seed=0)\n",
    "\n",
    "    input = Input(shape=(N_features, 4))\n",
    "    input_cat = Input(shape=(N_cat_features,))\n",
    "    input_MET = Input(shape=(2,))\n",
    "    unique_cat = 8\n",
    "    embedding_size = 100\n",
    "    \n",
    "    embedding_cat = Embedding(unique_cat, embedding_size)(input_cat)\n",
    "\n",
    "    x = concatenate([embedding_cat, input])\n",
    "\n",
    "    x = Bidirectional(LSTM(100, activation='relu', return_sequences=True, \n",
    "                           recurrent_dropout=0.125, kernel_initializer=initializer))(x)\n",
    "    x = Bidirectional(LSTM(100, activation='relu', recurrent_dropout=0.125, kernel_initializer=initializer))(x)\n",
    "\n",
    "    x_MET = Dense(64, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(input_MET) \n",
    "    merged = concatenate([x_MET, x])\n",
    "    x = Dense(64, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(merged)\n",
    "    output = Dense(5, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[input, input_cat, input_MET], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, \n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy(), 'Precision', 'Recall'])\n",
    "\n",
    "    if print_model:\n",
    "        print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "def multiclass_multioutput_LSTM(N_features, N_cat_features=0, print_model=True, learning_rate=1e-5):\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    initializer = tf.keras.initializers.HeNormal(seed=0)\n",
    "\n",
    "    input = Input(shape=(N_features, 4))\n",
    "    input_cat = Input(shape=(N_cat_features,))\n",
    "    input_MET = Input(shape=(2,))\n",
    "    unique_cat = 8\n",
    "    embedding_size = 100\n",
    "    embedding_cat = Embedding(unique_cat, embedding_size)(input_cat)\n",
    "\n",
    "    x = concatenate([embedding_cat, input])\n",
    "\n",
    "    x = Bidirectional(LSTM(100, activation='relu', return_sequences=True, recurrent_dropout=0.125, kernel_initializer=initializer))(x)\n",
    "    x = Bidirectional(LSTM(100, activation='relu', recurrent_dropout=0.125, kernel_initializer=initializer))(x)\n",
    "\n",
    "    x_MET = Dense(64, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(input_MET) \n",
    "    merged = concatenate([x_MET, x])\n",
    "    x = Dense(64, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(merged)\n",
    "    multiclass_output = Dense(5, activation='softmax')(x)\n",
    "    merged = concatenate([x, multiclass_output])\n",
    "    x = Dense(64, activation='relu', kernel_initializer=initializer, kernel_regularizer='l2')(x)\n",
    "    binary_output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[input, input_cat, input_MET], outputs=[binary_output, multiclass_output])\n",
    "    model.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=optimizer)\n",
    "\n",
    "    if print_model:\n",
    "        print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure for the simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "334/334 [==============================] - 3s 6ms/step - loss: 8.1169 - accuracy: 0.6994 - val_loss: 6.5458 - val_accuracy: 0.8416\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 6.2761 - accuracy: 0.8076 - val_loss: 5.2593 - val_accuracy: 0.8498\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 5.0384 - accuracy: 0.8264 - val_loss: 4.2868 - val_accuracy: 0.8518\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 4.1152 - accuracy: 0.8370 - val_loss: 3.5407 - val_accuracy: 0.8531\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 3.4087 - accuracy: 0.8389 - val_loss: 2.9601 - val_accuracy: 0.8540\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 2.8575 - accuracy: 0.8431 - val_loss: 2.5015 - val_accuracy: 0.8560\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 2.4260 - accuracy: 0.8438 - val_loss: 2.1346 - val_accuracy: 0.8549\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 2.0728 - accuracy: 0.8474 - val_loss: 1.8366 - val_accuracy: 0.8562\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 1.7863 - accuracy: 0.8498 - val_loss: 1.5915 - val_accuracy: 0.8577\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 1.5495 - accuracy: 0.8516 - val_loss: 1.3884 - val_accuracy: 0.8579\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 1.3524 - accuracy: 0.8533 - val_loss: 1.2195 - val_accuracy: 0.8570\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 1.1925 - accuracy: 0.8535 - val_loss: 1.0784 - val_accuracy: 0.8567\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 1.0539 - accuracy: 0.8544 - val_loss: 0.9591 - val_accuracy: 0.8579\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.9402 - accuracy: 0.8547 - val_loss: 0.8595 - val_accuracy: 0.8582\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.8423 - accuracy: 0.8564 - val_loss: 0.7761 - val_accuracy: 0.8583\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7624 - accuracy: 0.8571 - val_loss: 0.7056 - val_accuracy: 0.8581\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.6958 - accuracy: 0.8563 - val_loss: 0.6468 - val_accuracy: 0.8584\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.6392 - accuracy: 0.8548 - val_loss: 0.5974 - val_accuracy: 0.8569\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.5891 - accuracy: 0.8562 - val_loss: 0.5557 - val_accuracy: 0.8583\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.5497 - accuracy: 0.8565 - val_loss: 0.5195 - val_accuracy: 0.8580\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.5155 - accuracy: 0.8564 - val_loss: 0.4910 - val_accuracy: 0.8567\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.4858 - accuracy: 0.8575 - val_loss: 0.4642 - val_accuracy: 0.8583\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.4599 - accuracy: 0.8586 - val_loss: 0.4432 - val_accuracy: 0.8587\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.4439 - accuracy: 0.8553 - val_loss: 0.4251 - val_accuracy: 0.8587\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.4247 - accuracy: 0.8570 - val_loss: 0.4113 - val_accuracy: 0.8570\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.4111 - accuracy: 0.8573 - val_loss: 0.3986 - val_accuracy: 0.8570\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3992 - accuracy: 0.8577 - val_loss: 0.3896 - val_accuracy: 0.8577\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3867 - accuracy: 0.8588 - val_loss: 0.3805 - val_accuracy: 0.8584\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3804 - accuracy: 0.8582 - val_loss: 0.3743 - val_accuracy: 0.8599\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3747 - accuracy: 0.8575 - val_loss: 0.3689 - val_accuracy: 0.8583\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3684 - accuracy: 0.8591 - val_loss: 0.3650 - val_accuracy: 0.8579\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3665 - accuracy: 0.8578 - val_loss: 0.3619 - val_accuracy: 0.8571\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3621 - accuracy: 0.8585 - val_loss: 0.3589 - val_accuracy: 0.8597\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3615 - accuracy: 0.8581 - val_loss: 0.3563 - val_accuracy: 0.8579\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3576 - accuracy: 0.8587 - val_loss: 0.3548 - val_accuracy: 0.8588\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3573 - accuracy: 0.8589 - val_loss: 0.3535 - val_accuracy: 0.8596\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3571 - accuracy: 0.8574 - val_loss: 0.3543 - val_accuracy: 0.8570\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3529 - accuracy: 0.8586 - val_loss: 0.3512 - val_accuracy: 0.8596\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3514 - accuracy: 0.8591 - val_loss: 0.3506 - val_accuracy: 0.8603\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3532 - accuracy: 0.8578 - val_loss: 0.3501 - val_accuracy: 0.8600\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3512 - accuracy: 0.8590 - val_loss: 0.3489 - val_accuracy: 0.8581\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3489 - accuracy: 0.8607 - val_loss: 0.3485 - val_accuracy: 0.8601\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3474 - accuracy: 0.8606 - val_loss: 0.3475 - val_accuracy: 0.8597\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3483 - accuracy: 0.8596 - val_loss: 0.3473 - val_accuracy: 0.8591\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3475 - accuracy: 0.8601 - val_loss: 0.3461 - val_accuracy: 0.8592\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3469 - accuracy: 0.8600 - val_loss: 0.3459 - val_accuracy: 0.8608\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3471 - accuracy: 0.8591 - val_loss: 0.3464 - val_accuracy: 0.8589\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3466 - accuracy: 0.8600 - val_loss: 0.3455 - val_accuracy: 0.8593\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3462 - accuracy: 0.8605 - val_loss: 0.3449 - val_accuracy: 0.8590\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3455 - accuracy: 0.8596 - val_loss: 0.3438 - val_accuracy: 0.8598\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8622\n",
      "[0.34059980511665344, 0.8621500134468079]\n"
     ]
    }
   ],
   "source": [
    "df = read_data()\n",
    "TARGET = ['process ID']\n",
    "df, cat_df = prepare_input(df, particle_count=False)\n",
    "FEATURES = df.drop(['event weight', 'event ID', 'process ID'], axis=1).columns.to_list() \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(cat_df[[f'obj{x}' for x in range(1,11,1)]], cat_df[TARGET], test_size=0.1, \n",
    "                                                         shuffle=True, random_state=42, stratify=cat_df[TARGET])\n",
    "\n",
    "X_train = np.array([np.vstack(col) for col in X_train.values]) \n",
    "X_test = np.array([np.vstack(col) for col in X_test.values])\n",
    "X_train_cat = X_train_cat.to_numpy()\n",
    "X_test_cat = X_test_cat.to_numpy()\n",
    "y_train_enc = np.array(binary_encode_labels(y_train['process ID'])).astype(np.float32)\n",
    "y_test_enc = np.array(binary_encode_labels(y_test['process ID'])).astype(np.float32)\n",
    "\n",
    "simple_model = simple_net(len(X_train[0]), len(X_train_cat[0]), learning_rate=1e-4, print_model=False)\n",
    "history = simple_model.fit([X_train, X_train_cat], y_train_enc, batch_size=512, epochs=50, \n",
    "                                validation_split=0.05, verbose=1,  callbacks=[EarlyStopCallback])\n",
    "\n",
    "print(simple_model.evaluate([X_test, X_test_cat], y_test_enc))\n",
    "# tf.keras.models.save_model(simple_model, 'simple_NN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure for the simple Neural Network + Particle Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "334/334 [==============================] - 3s 6ms/step - loss: 8.6165 - accuracy: 0.6249 - val_loss: 6.7733 - val_accuracy: 0.8380\n",
      "Epoch 2/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 6.5767 - accuracy: 0.7918 - val_loss: 5.5642 - val_accuracy: 0.8502\n",
      "Epoch 3/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 5.3853 - accuracy: 0.8150 - val_loss: 4.6237 - val_accuracy: 0.8528\n",
      "Epoch 4/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 4.4752 - accuracy: 0.8283 - val_loss: 3.8789 - val_accuracy: 0.8534\n",
      "Epoch 5/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 3.7549 - accuracy: 0.8371 - val_loss: 3.2777 - val_accuracy: 0.8564\n",
      "Epoch 6/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 3.1781 - accuracy: 0.8424 - val_loss: 2.7903 - val_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 2.7070 - accuracy: 0.8457 - val_loss: 2.3896 - val_accuracy: 0.8561\n",
      "Epoch 8/50\n",
      "334/334 [==============================] - ETA: 0s - loss: 2.3214 - accuracy: 0.84 - 2s 7ms/step - loss: 2.3206 - accuracy: 0.8484 - val_loss: 2.0566 - val_accuracy: 0.8587\n",
      "Epoch 9/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 1.9987 - accuracy: 0.8524 - val_loss: 1.7787 - val_accuracy: 0.8587\n",
      "Epoch 10/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 1.7327 - accuracy: 0.8523 - val_loss: 1.5457 - val_accuracy: 0.8603\n",
      "Epoch 11/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 1.5070 - accuracy: 0.8555 - val_loss: 1.3538 - val_accuracy: 0.8590\n",
      "Epoch 12/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 1.3216 - accuracy: 0.8543 - val_loss: 1.1876 - val_accuracy: 0.8610\n",
      "Epoch 13/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 1.1611 - accuracy: 0.8566 - val_loss: 1.0519 - val_accuracy: 0.8598\n",
      "Epoch 14/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 1.0303 - accuracy: 0.8576 - val_loss: 0.9378 - val_accuracy: 0.8583\n",
      "Epoch 15/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.9194 - accuracy: 0.8575 - val_loss: 0.8402 - val_accuracy: 0.8598\n",
      "Epoch 16/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.8263 - accuracy: 0.8572 - val_loss: 0.7572 - val_accuracy: 0.8607\n",
      "Epoch 17/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.7465 - accuracy: 0.8579 - val_loss: 0.6869 - val_accuracy: 0.8621\n",
      "Epoch 18/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.6787 - accuracy: 0.8585 - val_loss: 0.6288 - val_accuracy: 0.8617\n",
      "Epoch 19/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.6202 - accuracy: 0.8590 - val_loss: 0.5796 - val_accuracy: 0.8626\n",
      "Epoch 20/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.5742 - accuracy: 0.8591 - val_loss: 0.5375 - val_accuracy: 0.8636\n",
      "Epoch 21/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.5349 - accuracy: 0.8601 - val_loss: 0.5021 - val_accuracy: 0.8630\n",
      "Epoch 22/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.4982 - accuracy: 0.8612 - val_loss: 0.4723 - val_accuracy: 0.8623\n",
      "Epoch 23/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.4709 - accuracy: 0.8604 - val_loss: 0.4489 - val_accuracy: 0.8632\n",
      "Epoch 24/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.4450 - accuracy: 0.8608 - val_loss: 0.4271 - val_accuracy: 0.8613\n",
      "Epoch 25/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.4264 - accuracy: 0.8617 - val_loss: 0.4093 - val_accuracy: 0.8628\n",
      "Epoch 26/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.4092 - accuracy: 0.8616 - val_loss: 0.3943 - val_accuracy: 0.8631\n",
      "Epoch 27/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3983 - accuracy: 0.8607 - val_loss: 0.3843 - val_accuracy: 0.8631\n",
      "Epoch 28/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3876 - accuracy: 0.8598 - val_loss: 0.3735 - val_accuracy: 0.8640\n",
      "Epoch 29/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3749 - accuracy: 0.8622 - val_loss: 0.3650 - val_accuracy: 0.8642\n",
      "Epoch 30/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3674 - accuracy: 0.8623 - val_loss: 0.3594 - val_accuracy: 0.8637\n",
      "Epoch 31/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3630 - accuracy: 0.8606 - val_loss: 0.3541 - val_accuracy: 0.8637\n",
      "Epoch 32/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3522 - accuracy: 0.8635 - val_loss: 0.3503 - val_accuracy: 0.8648\n",
      "Epoch 33/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3539 - accuracy: 0.8616 - val_loss: 0.3477 - val_accuracy: 0.8638\n",
      "Epoch 34/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3511 - accuracy: 0.8614 - val_loss: 0.3447 - val_accuracy: 0.8631\n",
      "Epoch 35/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3461 - accuracy: 0.8631 - val_loss: 0.3422 - val_accuracy: 0.8651\n",
      "Epoch 36/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3460 - accuracy: 0.8624 - val_loss: 0.3409 - val_accuracy: 0.8633\n",
      "Epoch 37/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3450 - accuracy: 0.8624 - val_loss: 0.3407 - val_accuracy: 0.8636\n",
      "Epoch 38/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3456 - accuracy: 0.8613 - val_loss: 0.3392 - val_accuracy: 0.8641\n",
      "Epoch 39/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3402 - accuracy: 0.8627 - val_loss: 0.3385 - val_accuracy: 0.8641\n",
      "Epoch 40/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3415 - accuracy: 0.8622 - val_loss: 0.3374 - val_accuracy: 0.8650\n",
      "Epoch 41/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3400 - accuracy: 0.8620 - val_loss: 0.3367 - val_accuracy: 0.8644\n",
      "Epoch 42/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3388 - accuracy: 0.8640 - val_loss: 0.3355 - val_accuracy: 0.8647\n",
      "Epoch 43/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3404 - accuracy: 0.8617 - val_loss: 0.3354 - val_accuracy: 0.8630\n",
      "Epoch 44/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3392 - accuracy: 0.8622 - val_loss: 0.3378 - val_accuracy: 0.8620\n",
      "Epoch 45/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3407 - accuracy: 0.8606 - val_loss: 0.3348 - val_accuracy: 0.8630\n",
      "Epoch 46/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3368 - accuracy: 0.8624 - val_loss: 0.3346 - val_accuracy: 0.8652\n",
      "Epoch 47/50\n",
      "334/334 [==============================] - 2s 5ms/step - loss: 0.3383 - accuracy: 0.8615 - val_loss: 0.3372 - val_accuracy: 0.8613\n",
      "Epoch 48/50\n",
      "334/334 [==============================] - 2s 6ms/step - loss: 0.3380 - accuracy: 0.8625 - val_loss: 0.3332 - val_accuracy: 0.8647\n",
      "Epoch 49/50\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3361 - accuracy: 0.8631 - val_loss: 0.3342 - val_accuracy: 0.8653\n",
      "Epoch 50/50\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3355 - accuracy: 0.8634 - val_loss: 0.3334 - val_accuracy: 0.8630\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 0.3303 - accuracy: 0.8669\n",
      "[0.33034491539001465, 0.8668500185012817]\n"
     ]
    }
   ],
   "source": [
    "df = read_data()\n",
    "TARGET = ['process ID']\n",
    "df, cat_df = prepare_input(df, particle_count=True)\n",
    "FEATURES = df.drop(['event weight', 'event ID', 'process ID'], axis=1).columns.to_list() \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(cat_df[[f'obj{x}' for x in range(1,11,1)]], cat_df[TARGET], test_size=0.1, \n",
    "                                                         shuffle=True, random_state=42, stratify=cat_df[TARGET])\n",
    "\n",
    "X_train = np.array([np.vstack(col) for col in X_train.values]) \n",
    "X_test = np.array([np.vstack(col) for col in X_test.values])\n",
    "X_train_cat = X_train_cat.to_numpy()\n",
    "X_test_cat = X_test_cat.to_numpy()\n",
    "y_train_enc = np.array(binary_encode_labels(y_train['process ID'])).astype(np.float32)\n",
    "y_test_enc = np.array(binary_encode_labels(y_test['process ID'])).astype(np.float32)\n",
    "\n",
    "simple_model = simple_net(len(X_train[0]), len(X_train_cat[0]), learning_rate=1e-4, print_model=False)\n",
    "history = simple_model.fit([X_train, X_train_cat], y_train_enc, batch_size=512, epochs=50, \n",
    "                                validation_split=0.05, verbose=1,  callbacks=[EarlyStopCallback])\n",
    "\n",
    "print(simple_model.evaluate([X_test, X_test_cat], y_test_enc))\n",
    "# tf.keras.models.save_model(simple_model, 'simple_NN+particlecount.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure for the binary LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "334/334 [==============================] - 147s 415ms/step - loss: 2.7401 - accuracy: 0.7677 - val_loss: 2.1397 - val_accuracy: 0.8629\n",
      "Epoch 2/25\n",
      "334/334 [==============================] - 135s 404ms/step - loss: 2.0343 - accuracy: 0.8631 - val_loss: 1.7582 - val_accuracy: 0.8660\n",
      "Epoch 3/25\n",
      "334/334 [==============================] - 142s 427ms/step - loss: 1.6918 - accuracy: 0.8670 - val_loss: 1.5179 - val_accuracy: 0.8644\n",
      "Epoch 4/25\n",
      "334/334 [==============================] - 139s 417ms/step - loss: 1.4746 - accuracy: 0.8666 - val_loss: 1.3559 - val_accuracy: 0.8683\n",
      "Epoch 5/25\n",
      "334/334 [==============================] - 121s 362ms/step - loss: 1.3264 - accuracy: 0.8682 - val_loss: 1.2433 - val_accuracy: 0.8692\n",
      "Epoch 6/25\n",
      "334/334 [==============================] - 122s 366ms/step - loss: 1.2231 - accuracy: 0.8670 - val_loss: 1.1609 - val_accuracy: 0.8671\n",
      "Epoch 7/25\n",
      "334/334 [==============================] - 120s 358ms/step - loss: 1.1446 - accuracy: 0.8676 - val_loss: 1.0948 - val_accuracy: 0.8690\n",
      "Epoch 8/25\n",
      "334/334 [==============================] - 123s 369ms/step - loss: 1.0805 - accuracy: 0.8677 - val_loss: 1.0405 - val_accuracy: 0.8680\n",
      "Epoch 9/25\n",
      "334/334 [==============================] - 119s 356ms/step - loss: 1.0245 - accuracy: 0.8692 - val_loss: 0.9900 - val_accuracy: 0.8693\n",
      "Epoch 10/25\n",
      "334/334 [==============================] - 123s 368ms/step - loss: 0.9765 - accuracy: 0.8693 - val_loss: 0.9474 - val_accuracy: 0.8686\n",
      "Epoch 11/25\n",
      "334/334 [==============================] - 123s 367ms/step - loss: 0.9338 - accuracy: 0.8703 - val_loss: 0.9055 - val_accuracy: 0.8687\n",
      "Epoch 12/25\n",
      "334/334 [==============================] - 119s 356ms/step - loss: 0.8927 - accuracy: 0.8714 - val_loss: 0.8687 - val_accuracy: 0.8687\n",
      "Epoch 13/25\n",
      "334/334 [==============================] - 119s 356ms/step - loss: 0.8562 - accuracy: 0.8695 - val_loss: 0.8324 - val_accuracy: 0.8684\n",
      "Epoch 14/25\n",
      "334/334 [==============================] - 161s 481ms/step - loss: 0.8193 - accuracy: 0.8696 - val_loss: 0.7991 - val_accuracy: 0.8692\n",
      "Epoch 15/25\n",
      "334/334 [==============================] - 169s 506ms/step - loss: 0.7867 - accuracy: 0.8700 - val_loss: 0.7658 - val_accuracy: 0.8687\n",
      "Epoch 16/25\n",
      "334/334 [==============================] - 190s 567ms/step - loss: 0.7530 - accuracy: 0.8711 - val_loss: 0.7353 - val_accuracy: 0.8689\n",
      "Epoch 17/25\n",
      "334/334 [==============================] - 170s 508ms/step - loss: 0.7257 - accuracy: 0.8706 - val_loss: 0.7083 - val_accuracy: 0.8681\n",
      "Epoch 18/25\n",
      "334/334 [==============================] - 171s 511ms/step - loss: 0.6961 - accuracy: 0.8708 - val_loss: 0.6785 - val_accuracy: 0.8688\n",
      "Epoch 19/25\n",
      "334/334 [==============================] - 172s 516ms/step - loss: 0.6694 - accuracy: 0.8707 - val_loss: 0.6559 - val_accuracy: 0.8670\n",
      "Epoch 20/25\n",
      "334/334 [==============================] - 170s 509ms/step - loss: 0.6426 - accuracy: 0.8706 - val_loss: 0.6298 - val_accuracy: 0.8699\n",
      "Epoch 21/25\n",
      "334/334 [==============================] - 185s 554ms/step - loss: 0.6196 - accuracy: 0.8709 - val_loss: 0.6062 - val_accuracy: 0.8678\n",
      "Epoch 22/25\n",
      "334/334 [==============================] - 171s 512ms/step - loss: 0.5965 - accuracy: 0.8711 - val_loss: 0.5847 - val_accuracy: 0.8686\n",
      "Epoch 23/25\n",
      "334/334 [==============================] - 170s 509ms/step - loss: 0.5779 - accuracy: 0.8700 - val_loss: 0.5646 - val_accuracy: 0.8698\n",
      "Epoch 24/25\n",
      "334/334 [==============================] - 173s 518ms/step - loss: 0.5554 - accuracy: 0.8715 - val_loss: 0.5447 - val_accuracy: 0.8688\n",
      "Epoch 25/25\n",
      "334/334 [==============================] - 171s 511ms/step - loss: 0.5360 - accuracy: 0.8716 - val_loss: 0.5291 - val_accuracy: 0.8676\n",
      "625/625 [==============================] - 18s 24ms/step - loss: 0.5245 - accuracy: 0.8692\n",
      "[0.5244830846786499, 0.8691999912261963]\n"
     ]
    }
   ],
   "source": [
    "df = read_data()\n",
    "TARGET = ['process ID']\n",
    "df, cat_df = prepare_input(df, particle_count=False)\n",
    "df = merge4Vectors(df)\n",
    "FEATURES = [f'4Vector{x}' for x in range(1,11,1)]\n",
    "MET_FEATURES = ['MET', 'METphi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_MET, X_test_MET, y_train, y_test = train_test_split(df[MET_FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(cat_df[[f'obj{x}' for x in range(1,11,1)]], cat_df[TARGET], test_size=0.1, \n",
    "                                                         shuffle=True, random_state=42, stratify=cat_df[TARGET])\n",
    "\n",
    "X_train = np.array([np.vstack(col) for col in X_train.values]) \n",
    "X_test = np.array([np.vstack(col) for col in X_test.values])\n",
    "X_train_cat = X_train_cat.to_numpy()\n",
    "X_test_cat = X_test_cat.to_numpy()\n",
    "X_train_MET = X_train_MET.to_numpy()\n",
    "X_test_MET = X_test_MET.to_numpy()\n",
    "y_train_enc = np.array(binary_encode_labels(y_train['process ID'])).astype(np.float32)\n",
    "y_test_enc = np.array(binary_encode_labels(y_test['process ID'])).astype(np.float32)\n",
    "\n",
    "recurrent_model = binary_LSTM(len(X_train[0]), len(X_train_cat[0]), False, learning_rate=1e-4)\n",
    "history = recurrent_model.fit([X_train, X_train_cat, X_train_MET], y_train_enc,  batch_size=512, epochs=25,  \n",
    "                              validation_split=0.05, verbose=1, callbacks=[EarlyStopCallback]) \n",
    "\n",
    "print(recurrent_model.evaluate([X_test, X_test_cat, X_test_MET], y_test_enc))\n",
    "# tf.keras.models.save_model(recurrent_model, 'LSTM_binary.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure for the multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "334/334 [==============================] - 169s 483ms/step - loss: 5.2798 - dense_10_loss: 0.5288 - dense_8_loss: 1.2436 - val_loss: 4.2088 - val_dense_10_loss: 0.3268 - val_dense_8_loss: 0.9677\n",
      "Epoch 2/25\n",
      "334/334 [==============================] - 162s 485ms/step - loss: 4.0467 - dense_10_loss: 0.3275 - dense_8_loss: 0.9621 - val_loss: 3.6117 - val_dense_10_loss: 0.3187 - val_dense_8_loss: 0.9531\n",
      "Epoch 3/25\n",
      "334/334 [==============================] - 165s 495ms/step - loss: 3.4954 - dense_10_loss: 0.3192 - dense_8_loss: 0.9491 - val_loss: 3.1895 - val_dense_10_loss: 0.3159 - val_dense_8_loss: 0.9485\n",
      "Epoch 4/25\n",
      "334/334 [==============================] - 161s 482ms/step - loss: 3.0975 - dense_10_loss: 0.3143 - dense_8_loss: 0.9413 - val_loss: 2.8734 - val_dense_10_loss: 0.3151 - val_dense_8_loss: 0.9416\n",
      "Epoch 5/25\n",
      "334/334 [==============================] - 164s 490ms/step - loss: 2.8002 - dense_10_loss: 0.3139 - dense_8_loss: 0.9326 - val_loss: 2.6359 - val_dense_10_loss: 0.3140 - val_dense_8_loss: 0.9398\n",
      "Epoch 6/25\n",
      "334/334 [==============================] - 161s 483ms/step - loss: 2.5823 - dense_10_loss: 0.3129 - dense_8_loss: 0.9360 - val_loss: 2.4517 - val_dense_10_loss: 0.3138 - val_dense_8_loss: 0.9381\n",
      "Epoch 7/25\n",
      "334/334 [==============================] - 162s 486ms/step - loss: 2.4022 - dense_10_loss: 0.3112 - dense_8_loss: 0.9295 - val_loss: 2.3082 - val_dense_10_loss: 0.3140 - val_dense_8_loss: 0.9389\n",
      "Epoch 8/25\n",
      "334/334 [==============================] - 159s 476ms/step - loss: 2.2682 - dense_10_loss: 0.3127 - dense_8_loss: 0.9310 - val_loss: 2.1932 - val_dense_10_loss: 0.3147 - val_dense_8_loss: 0.9396\n",
      "Epoch 9/25\n",
      "334/334 [==============================] - 163s 488ms/step - loss: 2.1537 - dense_10_loss: 0.3107 - dense_8_loss: 0.9292 - val_loss: 2.0935 - val_dense_10_loss: 0.3128 - val_dense_8_loss: 0.9373\n",
      "Epoch 10/25\n",
      "334/334 [==============================] - 159s 477ms/step - loss: 2.0611 - dense_10_loss: 0.3107 - dense_8_loss: 0.9279 - val_loss: 2.0099 - val_dense_10_loss: 0.3116 - val_dense_8_loss: 0.9345\n",
      "Epoch 11/25\n",
      "334/334 [==============================] - 163s 487ms/step - loss: 1.9905 - dense_10_loss: 0.3127 - dense_8_loss: 0.9315 - val_loss: 1.9428 - val_dense_10_loss: 0.3114 - val_dense_8_loss: 0.9349\n",
      "Epoch 12/25\n",
      "334/334 [==============================] - 159s 476ms/step - loss: 1.9206 - dense_10_loss: 0.3116 - dense_8_loss: 0.9275 - val_loss: 1.8845 - val_dense_10_loss: 0.3119 - val_dense_8_loss: 0.9338\n",
      "Epoch 13/25\n",
      "334/334 [==============================] - 164s 492ms/step - loss: 1.8614 - dense_10_loss: 0.3111 - dense_8_loss: 0.9246 - val_loss: 1.8309 - val_dense_10_loss: 0.3111 - val_dense_8_loss: 0.9315\n",
      "Epoch 14/25\n",
      "334/334 [==============================] - 161s 483ms/step - loss: 1.8071 - dense_10_loss: 0.3090 - dense_8_loss: 0.9213 - val_loss: 1.7856 - val_dense_10_loss: 0.3107 - val_dense_8_loss: 0.9310\n",
      "Epoch 15/25\n",
      "334/334 [==============================] - 163s 487ms/step - loss: 1.7665 - dense_10_loss: 0.3084 - dense_8_loss: 0.9244 - val_loss: 1.7473 - val_dense_10_loss: 0.3112 - val_dense_8_loss: 0.9322\n",
      "Epoch 16/25\n",
      "334/334 [==============================] - 158s 474ms/step - loss: 1.7282 - dense_10_loss: 0.3085 - dense_8_loss: 0.9251 - val_loss: 1.7118 - val_dense_10_loss: 0.3123 - val_dense_8_loss: 0.9317\n",
      "Epoch 17/25\n",
      "334/334 [==============================] - 164s 492ms/step - loss: 1.6857 - dense_10_loss: 0.3070 - dense_8_loss: 0.9195 - val_loss: 1.6739 - val_dense_10_loss: 0.3099 - val_dense_8_loss: 0.9297\n",
      "Epoch 18/25\n",
      "334/334 [==============================] - 159s 475ms/step - loss: 1.6589 - dense_10_loss: 0.3093 - dense_8_loss: 0.9231 - val_loss: 1.6418 - val_dense_10_loss: 0.3102 - val_dense_8_loss: 0.9282\n",
      "Epoch 19/25\n",
      "334/334 [==============================] - 161s 483ms/step - loss: 1.6205 - dense_10_loss: 0.3063 - dense_8_loss: 0.9180 - val_loss: 1.6131 - val_dense_10_loss: 0.3098 - val_dense_8_loss: 0.9283\n",
      "Epoch 20/25\n",
      "334/334 [==============================] - 163s 488ms/step - loss: 1.5944 - dense_10_loss: 0.3053 - dense_8_loss: 0.9209 - val_loss: 1.5877 - val_dense_10_loss: 0.3104 - val_dense_8_loss: 0.9291\n",
      "Epoch 21/25\n",
      "334/334 [==============================] - 159s 475ms/step - loss: 1.5720 - dense_10_loss: 0.3092 - dense_8_loss: 0.9209 - val_loss: 1.5591 - val_dense_10_loss: 0.3087 - val_dense_8_loss: 0.9271\n",
      "Epoch 22/25\n",
      "334/334 [==============================] - 162s 486ms/step - loss: 1.5451 - dense_10_loss: 0.3064 - dense_8_loss: 0.9214 - val_loss: 1.5384 - val_dense_10_loss: 0.3101 - val_dense_8_loss: 0.9282\n",
      "Epoch 23/25\n",
      "334/334 [==============================] - 161s 481ms/step - loss: 1.5147 - dense_10_loss: 0.3056 - dense_8_loss: 0.9146 - val_loss: 1.5120 - val_dense_10_loss: 0.3086 - val_dense_8_loss: 0.9252\n",
      "Epoch 24/25\n",
      "334/334 [==============================] - 165s 494ms/step - loss: 1.4959 - dense_10_loss: 0.3048 - dense_8_loss: 0.9180 - val_loss: 1.4911 - val_dense_10_loss: 0.3081 - val_dense_8_loss: 0.9252\n",
      "Epoch 25/25\n",
      "334/334 [==============================] - 158s 474ms/step - loss: 1.4711 - dense_10_loss: 0.3045 - dense_8_loss: 0.9136 - val_loss: 1.4740 - val_dense_10_loss: 0.3085 - val_dense_8_loss: 0.9267\n",
      "The accuracy score is: tf.Tensor(0.86975, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "df = read_data()\n",
    "TARGET = ['process ID']\n",
    "FEATURES = df.drop(['event weight', 'event ID', 'process ID'], axis=1).columns.to_list() \n",
    "LABELS =['4top', 'ttbar', 'ttbarHiggs', 'ttbarW', 'ttbarZ']\n",
    "\n",
    "df[[f'E{x}' for x in range(1,11,1)]] = np.log(df[[f'E{x}' for x in range(1,11,1)]].astype(float))\n",
    "df[[f'pt{x}' for x in range(1,11,1)]] = np.log(df[[f'pt{x}' for x in range(1,11,1)]].astype(float))\n",
    "df['MET'] = np.log(df['MET'].astype(float))\n",
    "df = apply_cat_encoder(df)\n",
    "df= apply_standard_scaler(df)\n",
    "df = df.fillna(0, axis=1) # fill up nan values in the four vectors op te particles. Safe to use on the whole dataframe as the other columns do not have nan values. \n",
    "df = merge4Vectors(df)\n",
    "\n",
    "cat_df = df[[f'obj{x}' for x in range(1,11,1)]+['process ID']]\n",
    "df.drop([f'obj{x}' for x in range(1,11,1)], axis=1, inplace=True)\n",
    "FEATURES = [f'4Vector{x}' for x in range(1,11,1)]\n",
    "\n",
    "MET_FEATURES = ['MET', 'METphi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_MET, X_test_MET, y_train, y_test = train_test_split(df[MET_FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(cat_df[[f'obj{x}' for x in range(1,11,1)]], cat_df[TARGET], test_size=0.1, \n",
    "                                                         shuffle=True, random_state=42, stratify=cat_df[TARGET])\n",
    "\n",
    "X_train = np.array([np.vstack(col) for col in X_train.values]).reshape(-1,10,4,1)  # X_train.to_numpy() # \n",
    "X_test =  np.array([np.vstack(col) for col in X_test.values]).reshape(-1,10,4,1) #X_test.to_numpy() #\n",
    "X_train_cat = X_train_cat.to_numpy()\n",
    "X_test_cat = X_test_cat.to_numpy()\n",
    "X_train_MET = X_train_MET.to_numpy()\n",
    "X_test_MET = X_test_MET.to_numpy()\n",
    "y_train_enc = np.array(multiclass_encode_labels(y_train['process ID'])).astype(np.float32)\n",
    "y_test_enc = np.array(multiclass_encode_labels(y_test['process ID'])).astype(np.float32)\n",
    "y_train_enc_bin = np.array(binary_encode_labels(y_train['process ID'])).astype(np.float32)\n",
    "y_test_enc_bin = np.array(binary_encode_labels(y_test['process ID'])).astype(np.float32)\n",
    "\n",
    "model = multiclass_multioutput_LSTM(len(X_train[0]), len(X_train_cat[0]), print_model=False, learning_rate=1e-4)\n",
    "history = model.fit([X_train, X_train_cat, X_train_MET], [y_train_enc_bin, y_train_enc], batch_size=512, epochs=25, validation_split=0.05, \n",
    "                              verbose=1, callbacks=[EarlyStopCallback])\n",
    "\n",
    "# tf.keras.models.save_model(recurrent_model, 'LSTM_multioutput.h5')\n",
    "predictions = model.predict([X_test, X_test_cat, X_test_MET])\n",
    "preds = np.array(predictions[0].flatten()  > 0.5, dtype=np.float32)\n",
    "print('The accuracy score is:', K.mean(K.equal(y_test_enc_bin, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure for the multiclass LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "334/334 [==============================] - 214s 614ms/step - loss: 6.0089 - categorical_accuracy: 0.4716 - precision: 0.7685 - recall: 0.1637 - val_loss: 3.0611 - val_categorical_accuracy: 0.5784 - val_precision: 0.8868 - val_recall: 0.3569\n",
      "Epoch 2/25\n",
      "334/334 [==============================] - 203s 608ms/step - loss: 5.0832 - categorical_accuracy: 0.5844 - precision: 0.8826 - recall: 0.3662 - val_loss: 2.7946 - val_categorical_accuracy: 0.5796 - val_precision: 0.8504 - val_recall: 0.3770\n",
      "Epoch 3/25\n",
      "334/334 [==============================] - 200s 599ms/step - loss: 4.7800 - categorical_accuracy: 0.5929 - precision: 0.8696 - recall: 0.3848 - val_loss: 2.5571 - val_categorical_accuracy: 0.5968 - val_precision: 0.8744 - val_recall: 0.3867\n",
      "Epoch 4/25\n",
      "334/334 [==============================] - 204s 609ms/step - loss: 4.5815 - categorical_accuracy: 0.5992 - precision: 0.8645 - recall: 0.3897 - val_loss: 2.3868 - val_categorical_accuracy: 0.5999 - val_precision: 0.8595 - val_recall: 0.4043\n",
      "Epoch 5/25\n",
      "334/334 [==============================] - 203s 608ms/step - loss: 4.4435 - categorical_accuracy: 0.5974 - precision: 0.8619 - recall: 0.3893 - val_loss: 2.2949 - val_categorical_accuracy: 0.5931 - val_precision: 0.8746 - val_recall: 0.3774\n",
      "Epoch 6/25\n",
      "334/334 [==============================] - 200s 599ms/step - loss: 4.3053 - categorical_accuracy: 0.6018 - precision: 0.8629 - recall: 0.3938 - val_loss: 2.1725 - val_categorical_accuracy: 0.5982 - val_precision: 0.8692 - val_recall: 0.3927\n",
      "Epoch 7/25\n",
      "334/334 [==============================] - 203s 608ms/step - loss: 4.1986 - categorical_accuracy: 0.6049 - precision: 0.8612 - recall: 0.3974 - val_loss: 2.0656 - val_categorical_accuracy: 0.6040 - val_precision: 0.8608 - val_recall: 0.4054\n",
      "Epoch 8/25\n",
      "334/334 [==============================] - 203s 608ms/step - loss: 4.1071 - categorical_accuracy: 0.6038 - precision: 0.8607 - recall: 0.3984 - val_loss: 2.0106 - val_categorical_accuracy: 0.6019 - val_precision: 0.8621 - val_recall: 0.3946\n",
      "Epoch 9/25\n",
      "334/334 [==============================] - 200s 598ms/step - loss: 4.0349 - categorical_accuracy: 0.6031 - precision: 0.8597 - recall: 0.3953 - val_loss: 1.9335 - val_categorical_accuracy: 0.6003 - val_precision: 0.8644 - val_recall: 0.3917\n",
      "Epoch 10/25\n",
      "334/334 [==============================] - 203s 609ms/step - loss: 3.9588 - categorical_accuracy: 0.6033 - precision: 0.8593 - recall: 0.3967 - val_loss: 1.8449 - val_categorical_accuracy: 0.6063 - val_precision: 0.8412 - val_recall: 0.4256\n",
      "Epoch 11/25\n",
      "334/334 [==============================] - 204s 611ms/step - loss: 3.8903 - categorical_accuracy: 0.6043 - precision: 0.8553 - recall: 0.4008 - val_loss: 1.8184 - val_categorical_accuracy: 0.6029 - val_precision: 0.8685 - val_recall: 0.3853\n",
      "Epoch 12/25\n",
      "334/334 [==============================] - 204s 611ms/step - loss: 3.8296 - categorical_accuracy: 0.6048 - precision: 0.8613 - recall: 0.4021 - val_loss: 1.7573 - val_categorical_accuracy: 0.5989 - val_precision: 0.8523 - val_recall: 0.3976\n",
      "Epoch 13/25\n",
      "334/334 [==============================] - 205s 615ms/step - loss: 3.7825 - categorical_accuracy: 0.6039 - precision: 0.8541 - recall: 0.3977 - val_loss: 1.7011 - val_categorical_accuracy: 0.6022 - val_precision: 0.8758 - val_recall: 0.3888\n",
      "Epoch 14/25\n",
      "334/334 [==============================] - 208s 623ms/step - loss: 3.7297 - categorical_accuracy: 0.6016 - precision: 0.8588 - recall: 0.3969 - val_loss: 1.6323 - val_categorical_accuracy: 0.6101 - val_precision: 0.8603 - val_recall: 0.4147\n",
      "Epoch 15/25\n",
      "334/334 [==============================] - 201s 603ms/step - loss: 3.6793 - categorical_accuracy: 0.6053 - precision: 0.8568 - recall: 0.4032 - val_loss: 1.6009 - val_categorical_accuracy: 0.6018 - val_precision: 0.8385 - val_recall: 0.4153\n",
      "Epoch 16/25\n",
      "334/334 [==============================] - 204s 611ms/step - loss: 3.6162 - categorical_accuracy: 0.6063 - precision: 0.8557 - recall: 0.4042 - val_loss: 1.5614 - val_categorical_accuracy: 0.6047 - val_precision: 0.8520 - val_recall: 0.4112\n",
      "Epoch 17/25\n",
      "334/334 [==============================] - 202s 605ms/step - loss: 3.5821 - categorical_accuracy: 0.6053 - precision: 0.8545 - recall: 0.4065 - val_loss: 1.5395 - val_categorical_accuracy: 0.5973 - val_precision: 0.8436 - val_recall: 0.4034\n",
      "Epoch 18/25\n",
      "334/334 [==============================] - 204s 612ms/step - loss: 3.5473 - categorical_accuracy: 0.6050 - precision: 0.8545 - recall: 0.4036 - val_loss: 1.4975 - val_categorical_accuracy: 0.6019 - val_precision: 0.8446 - val_recall: 0.4161\n",
      "Epoch 19/25\n",
      "334/334 [==============================] - 205s 613ms/step - loss: 3.5062 - categorical_accuracy: 0.6069 - precision: 0.8547 - recall: 0.4079 - val_loss: 1.4420 - val_categorical_accuracy: 0.6080 - val_precision: 0.8553 - val_recall: 0.4157\n",
      "Epoch 20/25\n",
      "334/334 [==============================] - 204s 611ms/step - loss: 3.4655 - categorical_accuracy: 0.6083 - precision: 0.8556 - recall: 0.4079 - val_loss: 1.4254 - val_categorical_accuracy: 0.6003 - val_precision: 0.8467 - val_recall: 0.4082\n",
      "Epoch 21/25\n",
      "334/334 [==============================] - 379s 1s/step - loss: 3.4436 - categorical_accuracy: 0.6052 - precision: 0.8528 - recall: 0.4059 - val_loss: 1.3869 - val_categorical_accuracy: 0.6059 - val_precision: 0.8539 - val_recall: 0.4136\n",
      "Epoch 22/25\n",
      "334/334 [==============================] - 409s 1s/step - loss: 3.4149 - categorical_accuracy: 0.6060 - precision: 0.8535 - recall: 0.4067 - val_loss: 1.3652 - val_categorical_accuracy: 0.6037 - val_precision: 0.8479 - val_recall: 0.4107\n",
      "Epoch 23/25\n",
      "334/334 [==============================] - 415s 1s/step - loss: 3.3742 - categorical_accuracy: 0.6093 - precision: 0.8510 - recall: 0.4110 - val_loss: 1.3287 - val_categorical_accuracy: 0.6091 - val_precision: 0.8488 - val_recall: 0.4222\n",
      "Epoch 24/25\n",
      "334/334 [==============================] - 433s 1s/step - loss: 3.3574 - categorical_accuracy: 0.6074 - precision: 0.8540 - recall: 0.4086 - val_loss: 1.3213 - val_categorical_accuracy: 0.6012 - val_precision: 0.8541 - val_recall: 0.4060\n",
      "Epoch 25/25\n",
      "334/334 [==============================] - 420s 1s/step - loss: 3.3339 - categorical_accuracy: 0.6069 - precision: 0.8507 - recall: 0.4081 - val_loss: 1.2715 - val_categorical_accuracy: 0.6104 - val_precision: 0.8454 - val_recall: 0.4296\n"
     ]
    }
   ],
   "source": [
    "df = read_data()\n",
    "TARGET = ['process ID']\n",
    "FEATURES = df.drop(['event weight', 'event ID', 'process ID'], axis=1).columns.to_list() \n",
    "LABELS =['4top', 'ttbar', 'ttbarHiggs', 'ttbarW', 'ttbarZ']\n",
    "PRIOR = get_prior(df['process ID'])\n",
    "class_weights = get_class_weights(df['process ID'])\n",
    "\n",
    "\n",
    "df[[f'E{x}' for x in range(1,11,1)]] = np.log(df[[f'E{x}' for x in range(1,11,1)]].astype(float))\n",
    "df[[f'pt{x}' for x in range(1,11,1)]] = np.log(df[[f'pt{x}' for x in range(1,11,1)]].astype(float))\n",
    "df['MET'] = np.log(df['MET'].astype(float))\n",
    "df = apply_cat_encoder(df)\n",
    "df = apply_standard_scaler(df)\n",
    "df = df.fillna(0, axis=1) # fill up nan values in the four vectors op te particles. Safe to use on the whole dataframe as the other columns do not have nan values. \n",
    "df = merge4Vectors(df)\n",
    "\n",
    "cat_df = df[[f'obj{x}' for x in range(1,11,1)]+['process ID']]\n",
    "df.drop([f'obj{x}' for x in range(1,11,1)], axis=1, inplace=True)\n",
    "FEATURES = [f'4Vector{x}' for x in range(1,11,1)]\n",
    "MET_FEATURES = ['MET', 'METphi']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_MET, X_test_MET, y_train, y_test = train_test_split(df[MET_FEATURES], df[TARGET], test_size=0.1, shuffle=True, random_state=42, stratify=df[TARGET])\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(cat_df[[f'obj{x}' for x in range(1,11,1)]], cat_df[TARGET], test_size=0.1, \n",
    "                                                         shuffle=True, random_state=42, stratify=cat_df[TARGET])\n",
    "\n",
    "X_train = np.array([np.vstack(col) for col in X_train.values]).reshape(-1,10,4,1) \n",
    "X_test =  np.array([np.vstack(col) for col in X_test.values]).reshape(-1,10,4,1) \n",
    "X_train_cat = X_train_cat.to_numpy()\n",
    "X_test_cat = X_test_cat.to_numpy()\n",
    "X_train_MET = X_train_MET.to_numpy()\n",
    "X_test_MET = X_test_MET.to_numpy()\n",
    "y_train_enc = np.array(multiclass_encode_labels(y_train['process ID'])).astype(np.float32)\n",
    "y_test_enc = np.array(multiclass_encode_labels(y_test['process ID'])).astype(np.float32)\n",
    "y_train_enc_bin = np.array(binary_encode_labels(y_train['process ID'])).astype(np.float32)\n",
    "y_test_enc_bin = np.array(binary_encode_labels(y_test['process ID'])).astype(np.float32)\n",
    "\n",
    "recurrent_model = multiclass_LSTM(len(X_train[0]), len(X_train_cat[0]), print_model=False, learning_rate=1e-4)\n",
    "history = recurrent_model.fit([X_train, X_train_cat, X_train_MET], y_train_enc, batch_size=512, epochs=25, validation_split=0.05, \n",
    "                              verbose=1, class_weight=class_weights, callbacks=[EarlyStopCallback])\n",
    "# tf.keras.models.save_model(recurrent_model, 'LSTM_multiclass.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for multiclass LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        4top       0.88      0.84      0.86     10000\n",
      "       ttbar       0.49      0.58      0.53      2500\n",
      "  ttbarHiggs       0.29      0.35      0.32      2500\n",
      "      ttbarW       0.34      0.44      0.39      2500\n",
      "      ttbarZ       0.30      0.16      0.21      2500\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     20000\n",
      "   macro avg       0.46      0.47      0.46     20000\n",
      "weighted avg       0.62      0.61      0.61     20000\n",
      " samples avg       0.61      0.61      0.61     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = recurrent_model.predict([X_test, X_test_cat, X_test_MET])\n",
    "predictions = (predictions == predictions.max(axis=1)[:,None]).astype(int)\n",
    "print(metrics.classification_report(y_test_enc, predictions, target_names=LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        4top       0.79      0.95      0.86     10000\n",
      "       ttbar       0.49      0.57      0.53      2500\n",
      "  ttbarHiggs       0.35      0.20      0.25      2500\n",
      "      ttbarW       0.36      0.42      0.39      2500\n",
      "      ttbarZ       0.34      0.09      0.14      2500\n",
      "\n",
      "   micro avg       0.64      0.64      0.64     20000\n",
      "   macro avg       0.47      0.45      0.43     20000\n",
      "weighted avg       0.59      0.64      0.59     20000\n",
      " samples avg       0.64      0.64      0.64     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "With prior\n",
    "\"\"\"\n",
    "\n",
    "predictions = recurrent_model.predict([X_test, X_test_cat, X_test_MET])\n",
    "post = np.array([np.array(vect*PRIOR) for vect in predictions])\n",
    "post = (post == post.max(axis=1)[:,None]).astype(int)\n",
    "print(metrics.classification_report(y_test_enc, post, target_names=LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        4top       0.94      0.58      0.72     10000\n",
      "       ttbar       0.49      0.58      0.53      2500\n",
      "  ttbarHiggs       0.20      0.48      0.28      2500\n",
      "      ttbarW       0.34      0.44      0.38      2500\n",
      "      ttbarZ       0.26      0.18      0.21      2500\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     20000\n",
      "   macro avg       0.45      0.45      0.43     20000\n",
      "weighted avg       0.63      0.50      0.54     20000\n",
      " samples avg       0.50      0.50      0.50     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "With inverse prior\n",
    "\"\"\"\n",
    "\n",
    "predictions = recurrent_model.predict([X_test, X_test_cat, X_test_MET])\n",
    "post = np.array([np.array(vect*(PRIOR**-1)) for vect in predictions])\n",
    "post = (post == post.max(axis=1)[:,None]).astype(int)\n",
    "print(metrics.classification_report(y_test_enc, post, target_names=LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTICLASS VISUALISATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# won't run on windows, generate plot on linux or colab\n",
    "tf.keras.utils.plot_model(recurrent_model, \"resnet.png\", show_shapes=False, show_layer_names=False, dpi=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = metrics.confusion_matrix(y_test_enc.argmax(axis=1), predictions.argmax(axis=1))\n",
    "df_cm = pd.DataFrame(matrix, index=LABELS, columns=LABELS)\n",
    "df_cm = df_cm.div(df_cm.sum(axis=1), axis=0)\n",
    "\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 8})\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
